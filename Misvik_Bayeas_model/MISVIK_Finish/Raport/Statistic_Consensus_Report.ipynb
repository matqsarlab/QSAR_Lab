{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3661ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from QSAR_Lab.Misvik_Bayeas_model.comparison import observe\n",
    "from QSAR_Lab.Misvik_Bayeas_model.models import CombinationModel\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ade047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258304d3",
   "metadata": {},
   "source": [
    "# OX test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd9f2df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a549 = pd.read_excel(\"../Data/OX/a549_data.xlsx\", sheet_name=1, index_col=0)\n",
    "test_a549 = pd.read_excel(\"../Data/OX/a549_data.xlsx\", sheet_name=2, index_col=0)\n",
    "toxic_a549 = pd.read_excel(\"../Data/OX/a549_data.xlsx\", sheet_name=3, index_col=0)\n",
    "\n",
    "train_beas = pd.read_excel(\"../Data/OX/beas_data.xlsx\", sheet_name=1, index_col=0)\n",
    "test_beas = pd.read_excel(\"../Data/OX/beas_data.xlsx\", sheet_name=2, index_col=0)\n",
    "toxic_beas = pd.read_excel(\"../Data/OX/beas_data.xlsx\", sheet_name=3, index_col=0)\n",
    "\n",
    "train_hep = pd.read_excel(\"../Data/OX/hepg2_data.xlsx\", sheet_name=1, index_col=0)\n",
    "test_hep = pd.read_excel(\"../Data/OX/hepg2_data.xlsx\", sheet_name=2, index_col=0)\n",
    "toxic_hep = pd.read_excel(\"../Data/OX/hepg2_data.xlsx\", sheet_name=3, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60fb66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe2(obs):\n",
    "    obs_val = obs.loc[:, \"y\"]\n",
    "    obs_val.sort_index(inplace=True)\n",
    "    return np.array(obs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72be21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ilosc toksycznych NMs w zbiorze testowym\n",
    "tox_in_test = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201d12a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a549 = CombinationModel(my_model, train_a549,test_a549,toxic_a549,tox_in_test)\n",
    "beas = CombinationModel(my_model, train_beas,test_beas,toxic_beas,tox_in_test)\n",
    "hep = CombinationModel(my_model, train_hep,test_hep,toxic_hep,tox_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f61970b",
   "metadata": {},
   "source": [
    "## Model A549 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c9354fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__predOnTest from func:  True\n",
      "CREATE_DATA - number of sets: 6970\n",
      "__predOnTest GLOBAL:  True\n",
      "ELSE\n",
      "[0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0]\n",
      "[1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "obs = pd.read_excel(\"../Data/OX/a549_data.xlsx\", index_col=0)\n",
    "obs = observe2(obs)\n",
    "\n",
    "pred = a549.predict_on_test\n",
    "pred.sort_index(inplace=True)\n",
    "pred = np.where(pred == \"Toxic\", 1, 0).flatten()\n",
    "\n",
    "print(obs)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38367095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5714285714285714\n",
      "Precison = 0.375\n",
      "Recall = 0.42857142857142855\n",
      "tn = 9\n",
      "fp = 5\n",
      "fn = 4\n",
      "tp = 3\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(obs, pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "acc = accuracy_score(obs, pred)\n",
    "prec = precision_score(obs, pred, average=\"binary\")\n",
    "rec = recall_score(obs, pred, average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy = {acc}\")\n",
    "print(f\"Precison = {prec}\")\n",
    "print(f\"Recall = {rec}\")\n",
    "print(f\"tn = {tn}\")\n",
    "print(f\"fp = {fp}\")\n",
    "print(f\"fn = {fn}\")\n",
    "print(f\"tp = {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7be219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49674f2c",
   "metadata": {},
   "source": [
    "## Model BEAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16cb9de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__predOnTest from func:  True\n",
      "CREATE_DATA - number of sets: 5358\n",
      "__predOnTest GLOBAL:  True\n",
      "ELSE\n",
      "[1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "obs = pd.read_excel(\"../Data/OX/beas_data.xlsx\", index_col=0)\n",
    "obs = observe2(obs)\n",
    "\n",
    "pred = beas.predict_on_test\n",
    "pred.sort_index(inplace=True)\n",
    "pred = np.where(pred == \"Toxic\", 1, 0).flatten()\n",
    "\n",
    "print(obs)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89e9221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9523809523809523\n",
      "Precison = 1.0\n",
      "Recall = 0.75\n",
      "tn = 17\n",
      "fp = 0\n",
      "fn = 1\n",
      "tp = 3\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(obs, pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "acc = accuracy_score(obs, pred)\n",
    "prec = precision_score(obs, pred, average=\"binary\")\n",
    "rec = recall_score(obs, pred, average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy = {acc}\")\n",
    "print(f\"Precison = {prec}\")\n",
    "print(f\"Recall = {rec}\")\n",
    "print(f\"tn = {tn}\")\n",
    "print(f\"fp = {fp}\")\n",
    "print(f\"fn = {fn}\")\n",
    "print(f\"tp = {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a27e9",
   "metadata": {},
   "source": [
    "## Model HEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b0cc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__predOnTest from func:  True\n",
      "CREATE_DATA - number of sets: 10465\n",
      "__predOnTest GLOBAL:  True\n",
      "ELSE\n",
      "[0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "obs = pd.read_excel(\"../Data/OX/hepg2_data.xlsx\", index_col=0)\n",
    "obs = observe2(obs)\n",
    "\n",
    "pred = hep.predict_on_test\n",
    "pred.sort_index(inplace=True)\n",
    "pred = np.where(pred == \"Toxic\", 1, 0).flatten()\n",
    "\n",
    "print(obs)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50af9625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8571428571428571\n",
      "Precison = 0.75\n",
      "Recall = 0.6\n",
      "tn = 15\n",
      "fp = 1\n",
      "fn = 2\n",
      "tp = 3\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(obs, pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "acc = accuracy_score(obs, pred)\n",
    "prec = precision_score(obs, pred, average=\"binary\")\n",
    "rec = recall_score(obs, pred, average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy = {acc}\")\n",
    "print(f\"Precison = {prec}\")\n",
    "print(f\"Recall = {rec}\")\n",
    "print(f\"tn = {tn}\")\n",
    "print(f\"fp = {fp}\")\n",
    "print(f\"fn = {fn}\")\n",
    "print(f\"tp = {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8297c942",
   "metadata": {},
   "source": [
    "# DNA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a8c87f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a549 = pd.read_excel(\"../Data/DNA/a549_data.xlsx\", sheet_name=1, index_col=0)\n",
    "test_a549 = pd.read_excel(\"../Data/DNA/a549_data.xlsx\", sheet_name=2, index_col=0)\n",
    "toxic_a549 = pd.read_excel(\"../Data/DNA/a549_data.xlsx\", sheet_name=3, index_col=0)\n",
    "\n",
    "train_beas = pd.read_excel(\"../Data/DNA/beas_data.xlsx\", sheet_name=1, index_col=0)\n",
    "test_beas = pd.read_excel(\"../Data/DNA/beas_data.xlsx\", sheet_name=2, index_col=0)\n",
    "toxic_beas = pd.read_excel(\"../Data/DNA/beas_data.xlsx\", sheet_name=3, index_col=0)\n",
    "\n",
    "train_hep = pd.read_excel(\"../Data/DNA/hepg2_data.xlsx\", sheet_name=1, index_col=0)\n",
    "test_hep = pd.read_excel(\"../Data/DNA/hepg2_data.xlsx\", sheet_name=2, index_col=0)\n",
    "toxic_hep = pd.read_excel(\"../Data/DNA/hepg2_data.xlsx\", sheet_name=3, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80732c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "a549 = CombinationModel(my_model, train_a549,test_a549,toxic_a549,tox_in_test)\n",
    "beas = CombinationModel(my_model, train_beas,test_beas,toxic_beas,tox_in_test)\n",
    "hep = CombinationModel(my_model, train_hep,test_hep,toxic_hep,tox_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42cc2d9",
   "metadata": {},
   "source": [
    "## Model A549 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b23bc2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__predOnTest from func:  True\n",
      "CREATE_DATA - number of sets: 10914\n",
      "__predOnTest GLOBAL:  True\n",
      "ELSE\n",
      "[0 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 1 1 0 1 0]\n",
      "[0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "obs = pd.read_excel(\"../Data/DNA/a549_data.xlsx\", index_col=0)\n",
    "obs = observe2(obs)\n",
    "\n",
    "pred = a549.predict_on_test\n",
    "pred.sort_index(inplace=True)\n",
    "pred = np.where(pred == \"Toxic\", 1, 0).flatten()\n",
    "\n",
    "print(obs)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67e4fee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.47619047619047616\n",
      "Precison = 0.4\n",
      "Recall = 0.2\n",
      "tn = 8\n",
      "fp = 3\n",
      "fn = 8\n",
      "tp = 2\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(obs, pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "acc = accuracy_score(obs, pred)\n",
    "prec = precision_score(obs, pred, average=\"binary\")\n",
    "rec = recall_score(obs, pred, average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy = {acc}\")\n",
    "print(f\"Precison = {prec}\")\n",
    "print(f\"Recall = {rec}\")\n",
    "print(f\"tn = {tn}\")\n",
    "print(f\"fp = {fp}\")\n",
    "print(f\"fn = {fn}\")\n",
    "print(f\"tp = {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e439e24",
   "metadata": {},
   "source": [
    "## Model BEAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19cb30ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__predOnTest from func:  True\n",
      "CREATE_DATA - number of sets: 8997\n",
      "__predOnTest GLOBAL:  True\n",
      "ELSE\n",
      "[0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0]\n",
      "[0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "obs = pd.read_excel(\"../Data/DNA/beas_data.xlsx\", index_col=0)\n",
    "obs = observe2(obs)\n",
    "\n",
    "pred = beas.predict_on_test\n",
    "pred.sort_index(inplace=True)\n",
    "pred = np.where(pred == \"Toxic\", 1, 0).flatten()\n",
    "\n",
    "print(obs)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9facf2a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6190476190476191\n",
      "Precison = 0.4\n",
      "Recall = 0.2857142857142857\n",
      "tn = 11\n",
      "fp = 3\n",
      "fn = 5\n",
      "tp = 2\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(obs, pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "acc = accuracy_score(obs, pred)\n",
    "prec = precision_score(obs, pred, average=\"binary\")\n",
    "rec = recall_score(obs, pred, average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy = {acc}\")\n",
    "print(f\"Precison = {prec}\")\n",
    "print(f\"Recall = {rec}\")\n",
    "print(f\"tn = {tn}\")\n",
    "print(f\"fp = {fp}\")\n",
    "print(f\"fn = {fn}\")\n",
    "print(f\"tp = {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee6ba4",
   "metadata": {},
   "source": [
    "## Model HEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bc4f865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__predOnTest from func:  True\n",
      "CREATE_DATA - number of sets: 8658\n",
      "__predOnTest GLOBAL:  True\n",
      "ELSE\n",
      "[0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0]\n",
      "[0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "obs = pd.read_excel(\"../Data/DNA/hepg2_data.xlsx\", index_col=0)\n",
    "obs = observe2(obs)\n",
    "\n",
    "pred = hep.predict_on_test\n",
    "pred.sort_index(inplace=True)\n",
    "pred = np.where(pred == \"Toxic\", 1, 0).flatten()\n",
    "\n",
    "print(obs)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67590a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7619047619047619\n",
      "Precison = 0.5\n",
      "Recall = 0.6\n",
      "tn = 13\n",
      "fp = 3\n",
      "fn = 2\n",
      "tp = 3\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(obs, pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "acc = accuracy_score(obs, pred)\n",
    "prec = precision_score(obs, pred, average=\"binary\")\n",
    "rec = recall_score(obs, pred, average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy = {acc}\")\n",
    "print(f\"Precison = {prec}\")\n",
    "print(f\"Recall = {rec}\")\n",
    "print(f\"tn = {tn}\")\n",
    "print(f\"fp = {fp}\")\n",
    "print(f\"fn = {fn}\")\n",
    "print(f\"tp = {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c48a95f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
